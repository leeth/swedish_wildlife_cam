AWSTemplateFormatVersion: '2010-09-09'
Description: 'Simple AWS Batch setup for wildlife pipeline testing'

Parameters:
  Environment:
    Type: String
    Default: production
    AllowedValues: [development, staging, production]
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC ID for the batch environment
  SubnetIds:
    Type: CommaDelimitedList
    Description: Subnet IDs for the batch environment

Resources:
  # S3 Bucket for data storage
  DataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub 'wildlife-test-${Environment}-${AWS::AccountId}'
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  # IAM Role for Batch Service
  BatchServiceRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'wildlife-batch-service-role-${Environment}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: batch.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSBatchServiceRole

  # IAM Role for Batch Jobs
  BatchJobRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'wildlife-batch-job-role-${Environment}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ecs-tasks.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                  - s3:ListBucket
                Resource:
                  - !GetAtt DataBucket.Arn
                  - !Sub '${DataBucket.Arn}/*'

  # IAM Role for EC2 Instances
  BatchInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'wildlife-batch-instance-role-${Environment}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                  - s3:ListBucket
                Resource:
                  - !GetAtt DataBucket.Arn
                  - !Sub '${DataBucket.Arn}/*'

  # Instance Profile for EC2
  BatchInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Roles:
        - !Ref BatchInstanceRole

  # Security Group
  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub 'wildlife-batch-sg-${Environment}'
      GroupDescription: Security group for wildlife batch jobs
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0

  # Batch Compute Environment
  ComputeEnvironment:
    Type: AWS::Batch::ComputeEnvironment
    Properties:
      ComputeEnvironmentName: !Sub 'wildlife-compute-${Environment}'
      Type: MANAGED
      State: ENABLED
      ServiceRole: !GetAtt BatchServiceRole.Arn
      ComputeResources:
        Type: EC2
        MinvCpus: 0
        MaxvCpus: 10
        DesiredvCpus: 0
        InstanceTypes:
          - m5.large
          - m5.xlarge
        Subnets: !Ref SubnetIds
        SecurityGroupIds:
          - !Ref SecurityGroup
        InstanceRole: !GetAtt BatchInstanceProfile.Arn
        Tags:
          Environment: !Ref Environment
          Application: wildlife-detection

  # Batch Job Queue
  JobQueue:
    Type: AWS::Batch::JobQueue
    Properties:
      JobQueueName: !Sub 'wildlife-queue-${Environment}'
      State: ENABLED
      Priority: 1
      ComputeEnvironmentOrder:
        - Order: 1
          ComputeEnvironment: !Ref ComputeEnvironment

  # Batch Job Definition
  JobDefinition:
    Type: AWS::Batch::JobDefinition
    Properties:
      JobDefinitionName: !Sub 'wildlife-job-${Environment}'
      Type: container
      PlatformCapabilities:
        - EC2
      ContainerProperties:
        Image: public.ecr.aws/docker/library/ubuntu:20.04
        Vcpus: 1
        Memory: 2048
        JobRoleArn: !GetAtt BatchJobRole.Arn
        ExecutionRoleArn: !GetAtt BatchJobRole.Arn
        Environment:
          - Name: AWS_DEFAULT_REGION
            Value: eu-north-1
          - Name: DATA_BUCKET
            Value: !Ref DataBucket
        Command:
          - /bin/bash
          - -c
          - |
            echo "Starting wildlife processing job"
            echo "Data bucket: $DATA_BUCKET"
            echo "Processing files..."
            sleep 30
            echo "Job completed successfully"
      RetryStrategy:
        Attempts: 3
      Timeout:
        AttemptDurationSeconds: 300

Outputs:
  DataBucket:
    Description: S3 bucket for data storage
    Value: !Ref DataBucket
    Export:
      Name: !Sub '${AWS::StackName}-DataBucket'
  
  JobQueue:
    Description: Batch job queue
    Value: !Ref JobQueue
    Export:
      Name: !Sub '${AWS::StackName}-JobQueue'
  
  JobDefinition:
    Description: Batch job definition
    Value: !Ref JobDefinition
    Export:
      Name: !Sub '${AWS::StackName}-JobDefinition'
  
  ComputeEnvironment:
    Description: Batch compute environment
    Value: !Ref ComputeEnvironment
    Export:
      Name: !Sub '${AWS::StackName}-ComputeEnvironment'
